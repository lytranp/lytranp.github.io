---
layout: post
mathjax: true
title: "Lift / Gain"
read: 15
secondary: datamining
date: 2020-12-05
---
### Lift

- To evaluate machine learning models, it depends on problems like regression and classification. There are possible metrics to assess performance in classification like accuracy, precision-recall, ROC curve and so on. Lift charts is one of them and used for classification tasks.

- Lift is a measure of the effectiveness of a predictive model calculated as the ratio between the results obtained with and without the predictive model

- Use **Cumulative gains** and **Lift charts** to measure model performance. Both charts consists of lift curve and a baseline. 

### Case study 1

- Train a model to predict if customer cancels subscription (churn = 1) or keeps it (churn = 0). This means that high predicted probability should correlate with a high actual churn rate. The higher predicted score, the more likely customer will churn. 

- After we predict the probability of churn, we want to target all users with a predicted score between 0.8 and 1.0 (because this is the group that has high probability of churn. )

- Predict churn probability of each customer (value between 0.0 and 1.0). Then, we divide into 10 groups: 0.0 - 0.1; 0.1 - 0.2; ...;0.9 - 1.0

- Calculate the **true churn rate** per group = {count the number of people who churned actually in each group / total number of customers per group}

- y-axis churn rate = true churn rate of each group. As we expected, true churn rate of the group [0.9 - 1.0] is high as predicted churn probability. The black line is predicted average churn rate and can use it as a threshold. E.g. customers with scores above threshold will be sent a discount to retain them.

![](/sources/lift1.png){:height="40%" width="40%"}

**Lift score** = {Predicted churn rate each group} / {Predicted average churn rate}

*Rate might be churn rate, response rate, conversion rate...*

- The highest group has a lift score = 0.97 / 0.2 = 4.85
  
- The second highest group has a lift score = 0.36 / 0.2 = 1.8

### Case study 2

- Based on 2 variables (Height, Age), built a model to predict probability of response. Then, order predict probability of response descending. 

- Divide into 10 equal groups with the number of customers equals. 

- Count the number of customer responded actually in each group. Then, compute cumulative the number of customer responded actually.

- Compute Cumulative Response Rate = Cumulative number of responses / Total number of responses (10)

![](/sources/lift2.png){:height="80%" width="80%"}

- Create **cumulative gains chart**
    
    + The y-axis: % positive responses on the total possible positive responses (Total positive Response = 10)

    + The x-axis: % customers contacted on total 20 customers (entire dataset)

    + Cumulative gains chart shows that if we use model to predict the probability of response and rank it descending, we will have chance of receiving 60% of response out of 40% of customers we sent email to (or 70% of response out of 50% of customers received the email). 

    + If we do not use the predictive model and only send email randomly to 40% of customers,the probability of response is also 40%. In another word, without the predictive model, the response probability of customers are 50-50 when we send email randomly. 

![](/sources/lift3.png){:height="40%" width="40%"}

- Create Lift Chart

    + From cumulative gain chart, we can compute **Lift score** at each group of customers contacted. For example, at 20% customers contacted, lift score = {Positive Response} / {Customers contacted} = 30/20 = 1.5. It means that by using model and contacting only 20% of customers based on the highest predicted response probability, it is likely 1.5 times as many respondents response our email. 

    + Lift chart shows how much more likely we are to receive respondents rather than we send emails randomly. 

![](/sources/lift4.png){:height="40%" width="40%"}

### Case study 3

- Train model and predict probabilities for each customer. Then, rank predicted probabilities in decreasing order.

- Split customers into equally sized segments (contain the same numbers of customers, but NOT necessarily equal about predicted probability range). Typically, split into 10 decile groups and each containing 10% of the customer base. So, those customers who are most likely to respond are in the decile group 1, the next most likely in the decile group 2, and so on. 

![](/sources/lift5.png){:height="80%" width="80%"}

- Because the decile group 1 has the highest predicted probability range, they also should have the highest actual response rate. As we expected, it is true. Actual respond rate is 14.3 % (143 respondents out of 1,000 customers), compared with the overall response rate of 5.1%.

![](/sources/lift6.png){:height="40%" width="40%"}

**Cumulative gain chart**

- We compare the cumulative % of customers who are responderst with cumulative % of customers contacted in the marketing campaign. 

- This graph describes "GAIN" in targeting because using the predictive model, we can get 28.3% of response from 10% of customers contacted. Including a further 10% customers (deciles 1 and 2), we find that out of the top 20% of customers,we will have around 51.6% of responses. 

![](/sources/lift7.png){:height="40%" width="40%"}

**Lift chart**

- As we see from example 2, we can know the formula of lift score. It compare % of responders and % of customers contacted. Therefore, if it is gain, lift > 1. 

![](/sources/lift8.png){:height="40%" width="40%"}

-----------------------------
References

https://www.kdnuggets.com/2016/03/lift-analysis-data-scientist-secret-weapon.html

http://www2.cs.uregina.ca/~dbd/cs831/notes/lift_chart/lift_chart.html

https://select-statistics.co.uk/blog/cumulative-gains-and-lift-curves-measuring-the-performance-of-a-marketing-campaign/
