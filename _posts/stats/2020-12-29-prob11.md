---
layout: post
mathjax: true
title: "Probability - Part 11 "
read: 15
secondary: prob&stat
date: 2020-12-29
---

In the [Part 10](https://lytranp.github.io/notes/prob10), we build up intuition about sampling distributions. So far, we have focused on the sampling distribution of sample means $M_Y$, but what we would really like to do is infer what the observed sample mean, $m_Y$, tells us about the population mean E(Y)

To make statistical inferences about the population (e.g, population mean), we have 2 types:

+ Estimate population parameters

+ Test hypotheses about parameters

### 1. Estimate population parameters - use Interval Estimation

The sample mean, $m_Y$ is a good point estimate of population mean. We want to know how reliable this estimate is. So, we need to calculate an **interval estimate** or **confidence interval** for the population mean E(Y).

+ Confidence interval (CI): is a range of numbers which most likely contain actual population value.

+ Confidence level (CL): is probability that interval actually contains the population value. We have to identify CL we want first because CL will decide CI.

=> True population belongs to (point estimate - uncertainty, point estimate + uncertainty)

![](/sources/prob11-3.png){:height="70%" width="70%"}

![](/sources/prob11-4.png){:height="70%" width="70%"}

Please see more [Examples](https://www.mathbootcamps.com/calculating-confidence-intervals-for-the-mean/)

*Example*: We want to calculate 95% CL for the population mean E(Y) about home prices. 95% CL means that you want an interval with area between 2 cutoff points (-1.96, 1.96). Because here, we use t-distribution with n-1 degrees of freedom, 2 cutoff points (-2.045, 2.045)

![](/sources/prob11-1.png){:height="50%" width="50%"}

**This probability statement also must be true for our observed sample statistics**, $m_Y$ = 278.6033 and $s_Y$ = 53.8556. So, to find values of E(Y), we plug in our sample statistics into formula

![](/sources/prob11-2.png){:height="50%" width="50%"}

=> **Interpretation**: 

+ We **cannot** say: "probability that population mean is in our interval is 95%" because we do not know whether 95% confidence interval for our particular sample contains the population mean. Additionally, the the population mean value is fixed.

+ Loosely speaking, 95% of the time, when we calculate a confidence interval in this way, the true mean will be between 2 values and 5% of the time, it will not. Because the true mean (population mean) is an unknown value, we do not know if we are in the 5% or 95%. But 95% is pretty good. So, we can say that: "we are 95% confidence that the mean of house sale price in the market is between 258,000 and 299,000". 

+ Strictly speaking, if we were to take a large number of random samples of size 30 from our population of sale prices and calculate 95% confidence interval for each, then 95% of those confidence intervals would contains the population mean. 

+ We do not always use 99% confidence level because the CL increases, the margin of error increases. That means that the interval is wider that makes conclusion to become useless. For example, "I am 99% confident that you will score between 10 and 100 on your next exam". This prediction seems not useful because the interval is too wide. 

### 2. Estimate population parameters - use Hypothesis Testing

Hypothesis testing is a procedure in inferential statistics. The sample data must provide sufficient evidence to reject the null hypothesis.

Suppose: a real estate agent claims that mean sale price in this market is 255,000 dollars. To check this information, you select a sample of size 30. After calculating from this sample, we have $m_Y$ = 278,6033 dollars and $s_Y$ = 53.8656. So, does information from our sample support the agent's claim or does it favor an alternative claim ? 

**Procedure to conduct a hypothesis test**

+ Null hypothesis $H_0$: parameter = some hypothesized value. H0 is equivalent to a presumption of innocence in a trial before any evidence has been presented

+ Alternative hypothesis $H_a$: can be a lower-tail form: E(Y) < 255; or upper-tail form: E(Y) > 255; or 2-tail form: E(Y) != 255

+ Calculate a test statistic based on the assumption that $H_0$ is true. Under the assumption that $H_0$ is true, this test statistic will have a particular probability distribution (e.g, t-distribution)

![](/sources/prob11-5.png){:height="70%" width="70%"}

+ To decide how far from zero a test statistic would have to be before we reject $H_0$ and favor $H_a$, we must make a decision about how much evidence we will require before rejecting $H_0$. There is always a chance that we might mistakenly reject $H_0$ when it is actually true. This chance is called the **significant level**.

+ Significant level dictates the critical value for the test. 

+ Another way to conduct a hypothesis test is to assume $H_0$ is true, but then to calculate the probability of observing a t-statistic as extreme (in the direction that favors $H_a$). This is called **p-value**. If p-value > significant level (0.05), this suggests that the evidence against $H_0$ is not strong enough, we can not reject $H_0$. And vice versa. Please see more explaination [p-value](https://s4be.cochrane.org/blog/2016/03/21/p-value-in-plain-english-2/#:~:text=In%20academic%20literature%2C%20the%20p,the%20null%20hypothesis%20were%20true)

![](/sources/prob11-6.png){:height="80%" width="80%"}

![](/sources/prob11-7.png){:height="40%" width="40%"}

### 3. Hypothesis test errors

Hypothesis testing has 2 types of errors: Type I and Type II

![](/sources/prob11-8.png){:height="60%" width="60%"}

+ Type I erros is when we reject $H_0$ although it is really true. It is equivalent to false alarm: fire alarm rings when there is no fire (False Positive). Even though we do not know for sure which studies have False Positive results, we do know their rate of occurrence. The rate of occurrence for Type I errors = significance level of the hypothesis test (also known as alpha $\alpha$)

+ Type II error rate (also known as beta $\beta$) is when we do not reject $H_0$ although it is really false. 1-$\beta$ = the statistical power = the probability of correctly detecting $H_a$ (effect exists). The shaded region on $H_a$ distribution represents the Type II error rate. The rest of alternative distribution represents the probability of correctly detecting an effect: called ***power***.
  
+ If we lower significance level, we reduce the chance of type I error occuring. Unfortunately, there is a tradeoff between Type I and Type II error. As you reduce the chance for False Positive, you increases the opportunity for False Negative. 

+ Moving the critical value line changes the significance level. Moving the line to the left, we are increasing signifciance level. This adjustment increases the Type I error rate, while reducing the Type II error rate.Moving the line to the right reduces the significance level, which decreases the Type I error rate, but increases the Type II error rate. 

![](/sources/prob11-9.png){:height="40%" width="40%"}

-----------------
**References**

https://statisticsbyjim.com/hypothesis-testing/types-errors-hypothesis-testing/
